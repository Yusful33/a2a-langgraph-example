{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Analysis Agent - Simplified Demo\n",
    "\n",
    "This notebook demonstrates a simplified stock analysis agent that:\n",
    "- Takes a **stock ticker** as input\n",
    "- Returns **bull** and **bear** cases from remote ADK agents\n",
    "- Uses **LangGraph** for orchestration\n",
    "- Connects via **A2A protocol** to remote agents\n",
    "- Sends traces to **Arize Cloud** with **auto-instrumentation enabled** for tool call capture\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Stock Ticker\n",
    "    â†“\n",
    "LangGraph Orchestrator\n",
    "    â†“\n",
    "A2A Protocol â†’ Bull Agent (LangGraph) + Bear Agent (ADK)\n",
    "    â†“\n",
    "Arize Cloud (Tracing with Tool Calls)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Version Check and Dependency Installation\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Check Python version\n",
    "python_version = sys.version_info\n",
    "print(f\"Python version: {python_version.major}.{python_version.minor}.{python_version.micro}\")\n",
    "\n",
    "if python_version.major == 3 and python_version.minor >= 14:\n",
    "    print(\"âš  Warning: Python 3.14+ detected. Some packages (like arize-otel) may require Python <3.14.\")\n",
    "    print(\"   Consider using Python 3.11 or 3.12 for full compatibility.\")\n",
    "    print()\n",
    "\n",
    "packages = [\n",
    "    \"langgraph>=0.2.0\",\n",
    "    \"langchain-anthropic>=0.3.0\",\n",
    "    \"langchain-core>=0.3.0\",\n",
    "    \"google-adk[a2a]>=1.20.0\",\n",
    "    \"a2a-sdk>=0.2.0\",\n",
    "    \"litellm>=1.75.5\",  # Required for provider-style models (anthropic/claude-sonnet-4-20250514)\n",
    "    \"arize-otel>=0.11.0\",  # May fail on Python 3.14+\n",
    "    \"opentelemetry-instrumentation-httpx>=0.45b0\",\n",
    "    \"opentelemetry-instrumentation-aiohttp-client>=0.45b0\",\n",
    "    \"openinference-instrumentation-langchain>=0.1.0\",  # For LangChain auto-instrumentation\n",
    "    \"python-dotenv>=1.0.0\",\n",
    "    \"httpx>=0.27.0\",\n",
    "]\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages, handling errors gracefully.\"\"\"\n",
    "    failed = []\n",
    "    for package in packages:\n",
    "        try:\n",
    "            # Use --break-system-packages if needed for externally-managed environments\n",
    "            cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--break-system-packages\", package]\n",
    "            subprocess.check_call(cmd, stderr=subprocess.DEVNULL)\n",
    "            print(f\"âœ“ Installed {package}\")\n",
    "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "            print(f\"âœ— Failed to install {package}\")\n",
    "            failed.append(package)\n",
    "    \n",
    "    if failed:\n",
    "        print(f\"\\nâš  {len(failed)} package(s) failed to install:\")\n",
    "        for pkg in failed:\n",
    "            print(f\"   - {pkg}\")\n",
    "        print(\"\\nYou may need to:\")\n",
    "        print(\"   1. Use Python 3.11 or 3.12 (recommended)\")\n",
    "        print(\"   2. Install manually: pip install --break-system-packages <package>\")\n",
    "        print(\"   3. Use a virtual environment\")\n",
    "\n",
    "# Uncomment to install packages\n",
    "# install_packages()\n",
    "\n",
    "print(\"Dependencies check complete. If packages are missing, uncomment install_packages() above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Imports\n",
    "\n",
    "import os\n",
    "from typing import TypedDict, List, Annotated\n",
    "from typing_extensions import Literal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Arize Cloud Configuration - Load from environment variables\n",
    "ARIZE_SPACE_ID = os.environ.get(\"ARIZE_SPACE_ID\")\n",
    "ARIZE_API_KEY = os.environ.get(\"ARIZE_API_KEY\")\n",
    "\n",
    "# Anthropic API Key - Load from environment variables\n",
    "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Validate required environment variables\n",
    "if not ARIZE_SPACE_ID:\n",
    "    raise ValueError(\"ARIZE_SPACE_ID environment variable is required. Please set it in your .env file or environment.\")\n",
    "if not ARIZE_API_KEY:\n",
    "    raise ValueError(\"ARIZE_API_KEY environment variable is required. Please set it in your .env file or environment.\")\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"ANTHROPIC_API_KEY environment variable is required. Please set it in your .env file or environment.\")\n",
    "\n",
    "# Set environment variables (for compatibility with other parts of the code)\n",
    "os.environ[\"ARIZE_SPACE_ID\"] = ARIZE_SPACE_ID\n",
    "os.environ[\"ARIZE_API_KEY\"] = ARIZE_API_KEY\n",
    "os.environ[\"ARIZE_PROJECT_NAME\"] = os.environ.get(\"ARIZE_PROJECT_NAME\", \"stock-analysis-notebook\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "\n",
    "print(f\"âœ“ Configured Arize Space ID: {ARIZE_SPACE_ID[:20]}...\")\n",
    "print(f\"âœ“ Configured Arize API Key: {ARIZE_API_KEY[:20]}...\")\n",
    "print(f\"âœ“ Configured Anthropic API Key: {ANTHROPIC_API_KEY[:20]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Arize Tracing with OpenTelemetry and Auto-Instrumentation\n",
    "\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.propagate import set_global_textmap\n",
    "from opentelemetry.propagators.composite import CompositePropagator\n",
    "from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator\n",
    "from opentelemetry.baggage.propagation import W3CBaggagePropagator\n",
    "\n",
    "# Set up W3C trace context propagation FIRST (before any tracer provider)\n",
    "set_global_textmap(CompositePropagator([\n",
    "    TraceContextTextMapPropagator(),\n",
    "    W3CBaggagePropagator()\n",
    "]))\n",
    "\n",
    "# Initialize Arize tracing\n",
    "try:\n",
    "    from arize.otel import register\n",
    "    \n",
    "    register(\n",
    "        space_id=ARIZE_SPACE_ID,\n",
    "        api_key=ARIZE_API_KEY,\n",
    "        project_name=\"stock-analysis-notebook\",\n",
    "        set_global_tracer_provider=True,\n",
    "        batch=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    # Re-set propagator after register (register might override it)\n",
    "    set_global_textmap(CompositePropagator([\n",
    "        TraceContextTextMapPropagator(),\n",
    "        W3CBaggagePropagator()\n",
    "    ]))\n",
    "    \n",
    "    print(\"âœ“ Arize tracing initialized via arize-otel\")\n",
    "    arize_available = True\n",
    "except ImportError:\n",
    "    # Fallback: Use OTLP exporter directly\n",
    "    print(\"âš  arize-otel not available, using OTLP exporter directly\")\n",
    "    try:\n",
    "        from opentelemetry.sdk.trace import TracerProvider\n",
    "        from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "        from opentelemetry.sdk.resources import Resource\n",
    "        from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "        \n",
    "        otlp_exporter = OTLPSpanExporter(\n",
    "            endpoint=\"https://otlp.arize.com/v1/traces\",\n",
    "            headers={\n",
    "                \"space_id\": ARIZE_SPACE_ID,\n",
    "                \"authorization\": f\"Bearer {ARIZE_API_KEY}\",\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        resource = Resource.create({\n",
    "            \"service.name\": \"stock-analysis-notebook\",\n",
    "            \"arize.project.name\": \"stock-analysis-notebook\",\n",
    "            \"arize.space_id\": ARIZE_SPACE_ID,\n",
    "        })\n",
    "        \n",
    "        provider = TracerProvider(resource=resource)\n",
    "        provider.add_span_processor(BatchSpanProcessor(otlp_exporter))\n",
    "        trace.set_tracer_provider(provider)\n",
    "        \n",
    "        print(\"âœ“ Arize tracing initialized via OTLP exporter\")\n",
    "        arize_available = True\n",
    "    except Exception as e:\n",
    "        print(f\"âš  Error setting up OTLP exporter: {e}\")\n",
    "        from opentelemetry.sdk.trace import TracerProvider\n",
    "        from opentelemetry.sdk.resources import Resource\n",
    "        provider = TracerProvider(resource=Resource.create({\"service.name\": \"stock-analysis-notebook\"}))\n",
    "        trace.set_tracer_provider(provider)\n",
    "        arize_available = False\n",
    "except Exception as e:\n",
    "    print(f\"âš  Error initializing Arize tracing: {e}\")\n",
    "    from opentelemetry.sdk.trace import TracerProvider\n",
    "    from opentelemetry.sdk.resources import Resource\n",
    "    provider = TracerProvider(resource=Resource.create({\"service.name\": \"stock-analysis-notebook\"}))\n",
    "    trace.set_tracer_provider(provider)\n",
    "    arize_available = False\n",
    "\n",
    "# Instrument HTTP clients for automatic trace propagation\n",
    "try:\n",
    "    from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor\n",
    "    HTTPXClientInstrumentor().instrument()\n",
    "    print(\"âœ“ HTTPX instrumentation enabled\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  HTTPX instrumentation failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from opentelemetry.instrumentation.aiohttp_client import AioHttpClientInstrumentor\n",
    "    AioHttpClientInstrumentor().instrument()\n",
    "    print(\"âœ“ AioHTTP instrumentation enabled\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  AioHTTP instrumentation failed: {e}\")\n",
    "\n",
    "# Enable LangChain auto-instrumentation for tool call capture\n",
    "try:\n",
    "    from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "    \n",
    "    # Get the tracer provider\n",
    "    tracer_provider = trace.get_tracer_provider()\n",
    "    \n",
    "    # Instrument LangChain - this will automatically capture:\n",
    "    # - LLM calls\n",
    "    # - Tool calls (from remote agents)\n",
    "    # - Chain executions\n",
    "    langchain_instrumentor = LangChainInstrumentor()\n",
    "    langchain_instrumentor.instrument(\n",
    "        tracer_provider=tracer_provider,\n",
    "        skip_dep_check=True\n",
    "    )\n",
    "    \n",
    "    print(\"âœ“ LangChain auto-instrumentation enabled (will capture tool calls from remote agents)\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš  LangChain instrumentor not available: {e}\")\n",
    "    print(\"   Install with: pip install openinference-instrumentation-langchain\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Error enabling LangChain instrumentation: {e}\")\n",
    "\n",
    "# Create tracer for manual spans\n",
    "tracer = trace.get_tracer(\"stock-analysis\")\n",
    "print(\"âœ“ Tracing setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Simplified LangGraph State\n",
    "\n",
    "from typing import TypedDict, List, Annotated\n",
    "import operator\n",
    "\n",
    "class StockAnalysisState(TypedDict):\n",
    "    \"\"\"Simplified state for stock analysis agent.\"\"\"\n",
    "    ticker: str  # Stock ticker symbol\n",
    "    bull_case: str  # Bullish analysis\n",
    "    bear_case: str  # Bearish analysis\n",
    "    analysis_steps: Annotated[List[str], operator.add]  # Steps taken\n",
    "\n",
    "print(\"âœ“ Simplified state schema defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Orchestrator A2A Endpoint and Start Server\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ORCHESTRATOR_ENDPOINT = os.environ.get(\"ORCHESTRATOR_URL\", \"http://localhost:8000\")\n",
    "ORCHESTRATOR_PORT = 8000\n",
    "\n",
    "# Find project root (parent of notebooks directory)\n",
    "current_dir = Path.cwd()\n",
    "if (current_dir / \"notebooks\").exists():\n",
    "    project_root = current_dir\n",
    "elif (current_dir.parent / \"notebooks\").exists():\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "def start_orchestrator_server():\n",
    "    \"\"\"Start the orchestrator server in a background process.\"\"\"\n",
    "    try:\n",
    "        # Start uvicorn server via subprocess (more reliable than threading)\n",
    "        # Use a log file to capture any startup errors\n",
    "        log_file = project_root / \".orchestrator.log\"\n",
    "        with open(log_file, \"w\") as f:\n",
    "            process = subprocess.Popen(\n",
    "                [sys.executable, \"-m\", \"uvicorn\", \"src.orchestrator.server:a2a_app\", \n",
    "                 \"--port\", str(ORCHESTRATOR_PORT), \"--host\", \"0.0.0.0\", \"--log-level\", \"error\"],\n",
    "                cwd=project_root,\n",
    "                stdout=f,\n",
    "                stderr=subprocess.STDOUT\n",
    "            )\n",
    "        return process\n",
    "    except Exception as e:\n",
    "        print(f\"âš  Orchestrator server error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Check if orchestrator is already running\n",
    "orchestrator_running = False\n",
    "try:\n",
    "    import httpx\n",
    "    with httpx.Client(timeout=2.0) as client:\n",
    "        response = client.get(f\"{ORCHESTRATOR_ENDPOINT}/.well-known/agent-card.json\")\n",
    "        if response.status_code == 200:\n",
    "            orchestrator_running = True\n",
    "            print(f\"âœ“ Orchestrator is already running at {ORCHESTRATOR_ENDPOINT}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Start orchestrator if not running\n",
    "orchestrator_process = None\n",
    "if not orchestrator_running:\n",
    "    print(f\"ðŸš€ Starting orchestrator server on port {ORCHESTRATOR_PORT}...\")\n",
    "    print(f\"   Project root: {project_root}\")\n",
    "    try:\n",
    "        # Start server in background\n",
    "        orchestrator_process = start_orchestrator_server()\n",
    "        \n",
    "        if orchestrator_process:\n",
    "            # Wait for server to be ready\n",
    "            max_wait = 10\n",
    "            for i in range(max_wait):\n",
    "                time.sleep(1)\n",
    "                try:\n",
    "                    import httpx\n",
    "                    with httpx.Client(timeout=2.0) as client:\n",
    "                        response = client.get(f\"{ORCHESTRATOR_ENDPOINT}/.well-known/agent-card.json\")\n",
    "                        if response.status_code == 200:\n",
    "                            print(f\"âœ“ Orchestrator started successfully at {ORCHESTRATOR_ENDPOINT}\")\n",
    "                            orchestrator_running = True\n",
    "                            break\n",
    "                except:\n",
    "                    if i < max_wait - 1:\n",
    "                        print(f\"   Waiting for orchestrator... ({i+1}/{max_wait})\")\n",
    "                    else:\n",
    "                        # Check log file for errors\n",
    "                        log_file = project_root / \".orchestrator.log\"\n",
    "                        if log_file.exists():\n",
    "                            with open(log_file, \"r\") as f:\n",
    "                                log_content = f.read()\n",
    "                                if log_content:\n",
    "                                    print(f\"âš  Orchestrator startup errors (see {log_file}):\")\n",
    "                                    print(f\"   {log_content[:500]}\")\n",
    "                        print(f\"âš  Orchestrator may not have started. Continuing anyway...\")\n",
    "                        print(f\"   You can start it manually: cd {project_root} && uvicorn src.orchestrator.server:a2a_app --port {ORCHESTRATOR_PORT}\")\n",
    "        else:\n",
    "            print(f\"âš  Could not start orchestrator process\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš  Could not start orchestrator automatically: {e}\")\n",
    "        print(f\"   Please start it manually: cd {project_root} && uvicorn src.orchestrator.server:a2a_app --port {ORCHESTRATOR_PORT}\")\n",
    "\n",
    "if not orchestrator_running:\n",
    "    print(f\"\\nâš  Orchestrator Endpoint: {ORCHESTRATOR_ENDPOINT}\")\n",
    "    print(\"âš  Ensure the orchestrator is running locally or update URL to remote endpoint\")\n",
    "    print(\"   The orchestrator will route queries to the appropriate agent (Bull or Bear)\")\n",
    "\n",
    "# Also check if Bull and Bear agents are running (orchestrator needs them)\n",
    "print(\"\\nðŸ“‹ Agent Status Check:\")\n",
    "\n",
    "def start_agent_server(agent_name: str, port: int, module_path: str):\n",
    "    \"\"\"Start an agent server in a background process.\"\"\"\n",
    "    try:\n",
    "        log_file = project_root / f\".{agent_name}.log\"\n",
    "        with open(log_file, \"w\") as f:\n",
    "            process = subprocess.Popen(\n",
    "                [sys.executable, \"-m\", \"uvicorn\", module_path, \n",
    "                 \"--port\", str(port), \"--host\", \"0.0.0.0\", \"--log-level\", \"error\"],\n",
    "                cwd=project_root,\n",
    "                stdout=f,\n",
    "                stderr=subprocess.STDOUT\n",
    "            )\n",
    "        return process\n",
    "    except Exception as e:\n",
    "        print(f\"âš  {agent_name} server error: {e}\")\n",
    "        return None\n",
    "\n",
    "bull_running = False\n",
    "bear_running = False\n",
    "bull_process = None\n",
    "bear_process = None\n",
    "\n",
    "# Check Bull Agent\n",
    "try:\n",
    "    import httpx\n",
    "    with httpx.Client(timeout=2.0) as client:\n",
    "        response = client.get(\"http://localhost:8001/.well-known/agent-card.json\")\n",
    "        if response.status_code == 200:\n",
    "            bull_running = True\n",
    "            print(\"  âœ“ Bull Agent (port 8001): Running\")\n",
    "except:\n",
    "    print(\"  âœ— Bull Agent (port 8001): Not running\")\n",
    "    print(\"     Starting Bull Agent...\")\n",
    "    try:\n",
    "        bull_process = start_agent_server(\"bull_agent\", 8001, \"src.bull_agent.server:a2a_app\")\n",
    "        if bull_process:\n",
    "            # Wait for server to be ready\n",
    "            for i in range(10):\n",
    "                time.sleep(1)\n",
    "                try:\n",
    "                    with httpx.Client(timeout=2.0) as client:\n",
    "                        response = client.get(\"http://localhost:8001/.well-known/agent-card.json\")\n",
    "                        if response.status_code == 200:\n",
    "                            bull_running = True\n",
    "                            print(\"  âœ“ Bull Agent started successfully\")\n",
    "                            break\n",
    "                except:\n",
    "                    if i == 9:\n",
    "                        print(\"  âš  Bull Agent may not have started\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Could not start Bull Agent: {e}\")\n",
    "\n",
    "# Check Bear Agent\n",
    "try:\n",
    "    import httpx\n",
    "    with httpx.Client(timeout=2.0) as client:\n",
    "        response = client.get(\"http://localhost:8002/.well-known/agent-card.json\")\n",
    "        if response.status_code == 200:\n",
    "            bear_running = True\n",
    "            print(\"  âœ“ Bear Agent (port 8002): Running\")\n",
    "except:\n",
    "    print(\"  âœ— Bear Agent (port 8002): Not running\")\n",
    "    print(\"     Starting Bear Agent...\")\n",
    "    try:\n",
    "        bear_process = start_agent_server(\"bear_agent\", 8002, \"src.bear_agent.server:a2a_app\")\n",
    "        if bear_process:\n",
    "            # Wait for server to be ready\n",
    "            for i in range(10):\n",
    "                time.sleep(1)\n",
    "                try:\n",
    "                    with httpx.Client(timeout=2.0) as client:\n",
    "                        response = client.get(\"http://localhost:8002/.well-known/agent-card.json\")\n",
    "                        if response.status_code == 200:\n",
    "                            bear_running = True\n",
    "                            print(\"  âœ“ Bear Agent started successfully\")\n",
    "                            break\n",
    "                except:\n",
    "                    if i == 9:\n",
    "                        print(\"  âš  Bear Agent may not have started\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Could not start Bear Agent: {e}\")\n",
    "\n",
    "if not bull_running or not bear_running:\n",
    "    print(\"\\nâš  Note: Orchestrator requires both Bull and Bear agents to be running for full functionality.\")\n",
    "    if not bull_running:\n",
    "        print(\"   Start Bull Agent: cd {project_root} && uvicorn src.bull_agent.server:a2a_app --port 8001\")\n",
    "    if not bear_running:\n",
    "        print(\"   Start Bear Agent: cd {project_root} && uvicorn src.bear_agent.server:a2a_app --port 8002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LangGraph Node Functions\n",
    "\n",
    "import httpx\n",
    "import uuid\n",
    "import time\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from opentelemetry.propagate import inject\n",
    "\n",
    "# OpenInference semantic convention constants\n",
    "OPENINFERENCE_SPAN_KIND = \"openinference.span.kind\"\n",
    "SPAN_KIND_AGENT = \"AGENT\"\n",
    "SPAN_KIND_TOOL = \"TOOL\"\n",
    "SPAN_KIND_LLM = \"LLM\"\n",
    "SPAN_KIND_CHAIN = \"CHAIN\"\n",
    "\n",
    "# Input/Output semantic conventions\n",
    "INPUT_VALUE = \"input.value\"\n",
    "INPUT_MIME_TYPE = \"input.mime_type\"\n",
    "OUTPUT_VALUE = \"output.value\"\n",
    "OUTPUT_MIME_TYPE = \"output.mime_type\"\n",
    "\n",
    "# Tool semantic conventions\n",
    "TOOL_NAME = \"tool.name\"\n",
    "TOOL_DESCRIPTION = \"tool.description\"\n",
    "TOOL_INPUT = \"tool.input\"\n",
    "TOOL_OUTPUT = \"tool.output\"\n",
    "\n",
    "# A2A Protocol semantic conventions\n",
    "A2A_AGENT = \"a2a.agent\"\n",
    "A2A_PROTOCOL = \"a2a.protocol\"\n",
    "A2A_METHOD = \"a2a.method\"\n",
    "A2A_MESSAGE_ID = \"a2a.message_id\"\n",
    "A2A_TASK_ID = \"a2a.task_id\"\n",
    "\n",
    "# HTTP semantic conventions\n",
    "HTTP_METHOD = \"http.method\"\n",
    "HTTP_URL = \"http.url\"\n",
    "HTTP_STATUS_CODE = \"http.status_code\"\n",
    "HTTP_REQUEST_HEADERS = \"http.request.headers\"\n",
    "HTTP_RESPONSE_HEADERS = \"http.response.headers\"\n",
    "\n",
    "# MCP semantic conventions (if applicable)\n",
    "MCP_SERVER = \"mcp.server\"\n",
    "MCP_TRANSPORT = \"mcp.transport\"\n",
    "MCP_TOOL_NAME = \"mcp.tool.name\"\n",
    "\n",
    "# LLM semantic conventions\n",
    "LLM_MODEL_NAME = \"llm.model_name\"\n",
    "LLM_INPUT_MESSAGES = \"llm.input.messages\"\n",
    "LLM_OUTPUT_MESSAGES = \"llm.output.messages\"\n",
    "LLM_TOKEN_COUNT_PROMPT = \"llm.token_count.prompt\"\n",
    "LLM_TOKEN_COUNT_COMPLETION = \"llm.token_count.completion\"\n",
    "LLM_TOKEN_COUNT_TOTAL = \"llm.token_count.total\"\n",
    "LLM_USAGE_PROMPT_TOKENS = \"llm.usage.prompt_tokens\"\n",
    "LLM_USAGE_COMPLETION_TOKENS = \"llm.usage.completion_tokens\"\n",
    "LLM_USAGE_TOTAL_TOKENS = \"llm.usage.total_tokens\"\n",
    "\n",
    "# Model pricing (Claude Sonnet 4 - 20250514)\n",
    "MODEL_COSTS = {\n",
    "    \"claude-sonnet-4-20250514\": {\"input\": 3.0, \"output\": 15.0},  # per 1M tokens\n",
    "    \"anthropic/claude-sonnet-4-20250514\": {\"input\": 3.0, \"output\": 15.0},\n",
    "}\n",
    "\n",
    "def estimate_tokens(text: str) -> int:\n",
    "    \"\"\"Rough token estimation: ~4 characters per token.\"\"\"\n",
    "    return len(text) // 4\n",
    "\n",
    "def calculate_llm_cost(model_name: str, prompt_tokens: int, completion_tokens: int) -> dict:\n",
    "    \"\"\"Calculate LLM cost based on model pricing.\"\"\"\n",
    "    costs = MODEL_COSTS.get(model_name, {\"input\": 0.0, \"output\": 0.0})\n",
    "    input_cost = (prompt_tokens / 1_000_000) * costs[\"input\"]\n",
    "    output_cost = (completion_tokens / 1_000_000) * costs[\"output\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "    return {\n",
    "        \"input_cost\": input_cost,\n",
    "        \"output_cost\": output_cost,\n",
    "        \"total_cost\": total_cost\n",
    "    }\n",
    "\n",
    "def add_timing_attributes(span, start_time: float = None):\n",
    "    \"\"\"Add timing attributes to a span for better visibility in trace data.\n",
    "    \n",
    "    Args:\n",
    "        span: The OpenTelemetry span\n",
    "        start_time: Optional start time (if None, uses current time)\n",
    "    \"\"\"\n",
    "    if start_time is None:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # Add start time as Unix timestamp (seconds since epoch)\n",
    "    span.set_attribute(\"span.start_time\", start_time)\n",
    "    span.set_attribute(\"span.start_time_iso\", time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\", time.gmtime(start_time)))\n",
    "    \n",
    "    # Calculate duration when span ends\n",
    "    # Note: OpenTelemetry automatically tracks duration, but we'll add it as an attribute too\n",
    "    # The actual duration will be set when the span ends via the context manager\n",
    "    return start_time\n",
    "\n",
    "def finalize_span_timing(span, start_time: float):\n",
    "    \"\"\"Finalize timing attributes for a span.\n",
    "    \n",
    "    Args:\n",
    "        span: The OpenTelemetry span\n",
    "        start_time: The start time from add_timing_attributes\n",
    "    \"\"\"\n",
    "    end_time = time.time()\n",
    "    duration_ms = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "    \n",
    "    span.set_attribute(\"span.end_time\", end_time)\n",
    "    span.set_attribute(\"span.end_time_iso\", time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\", time.gmtime(end_time)))\n",
    "    span.set_attribute(\"span.duration_ms\", duration_ms)\n",
    "    span.set_attribute(\"span.duration_seconds\", duration_ms / 1000.0)\n",
    "    \n",
    "    return duration_ms\n",
    "\n",
    "def query_orchestrator(state: StockAnalysisState) -> StockAnalysisState:\n",
    "    \"\"\"Query the orchestrator which will route to the appropriate agent (Bull or Bear) based on intent.\"\"\"\n",
    "    ticker = state[\"ticker\"].upper()\n",
    "    query = f\"Analyze {ticker} stock\"\n",
    "    \n",
    "    # Create main span for orchestrator query\n",
    "    with tracer.start_as_current_span(\"query_orchestrator\", kind=trace.SpanKind.CLIENT) as span:\n",
    "        span_start_time = add_timing_attributes(span)\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "        span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "        span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_AGENT)\n",
    "        span.set_attribute(A2A_AGENT, \"orchestrator\")\n",
    "        span.set_attribute(A2A_PROTOCOL, True)\n",
    "        span.set_attribute(\"stock.ticker\", ticker)\n",
    "        span.set_attribute(\"orchestrator.endpoint\", ORCHESTRATOR_ENDPOINT)\n",
    "        \n",
    "        span.set_attribute(INPUT_VALUE, query)\n",
    "        span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "        span.add_event(\"orchestrator.query.received\", {\"ticker\": ticker, \"query_length\": len(query)})\n",
    "        \n",
    "        try:\n",
    "            # Create span for routing decision (orchestrator will make this decision)\n",
    "            with tracer.start_as_current_span(\"orchestrator.intent_analysis\", kind=trace.SpanKind.INTERNAL) as routing_span:\n",
    "                routing_start_time = add_timing_attributes(routing_span)\n",
    "                routing_span.set_status(Status(StatusCode.OK))\n",
    "                routing_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                routing_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_CHAIN)\n",
    "                routing_span.set_attribute(\"routing.query\", query)\n",
    "                routing_span.add_event(\"routing.analysis.started\", {\"query\": query})\n",
    "                \n",
    "                try:\n",
    "                    # Create LLM span for orchestrator's routing decision\n",
    "                    with tracer.start_as_current_span(\"llm.orchestrator_routing\", kind=trace.SpanKind.CLIENT) as routing_llm_span:\n",
    "                        llm_start_time = add_timing_attributes(routing_llm_span)\n",
    "                        routing_llm_span.set_status(Status(StatusCode.OK))\n",
    "                        routing_llm_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                        routing_llm_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_LLM)\n",
    "                        routing_llm_span.set_attribute(LLM_MODEL_NAME, \"claude-sonnet-4-20250514\")\n",
    "                        routing_llm_span.set_attribute(A2A_AGENT, \"orchestrator\")\n",
    "                        routing_llm_span.set_attribute(\"llm.executed_by\", \"orchestrator\")\n",
    "                        routing_llm_span.set_attribute(\"llm.system\", \"anthropic\")\n",
    "                        routing_llm_span.set_attribute(INPUT_VALUE, query)\n",
    "                        routing_llm_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "                        \n",
    "                        # Estimate tokens for routing decision\n",
    "                        routing_prompt_tokens = estimate_tokens(query) + 300  # Query + routing prompt overhead\n",
    "                        routing_completion_tokens = 50  # Small completion for routing decision\n",
    "                        \n",
    "                        routing_llm_span.set_attribute(LLM_TOKEN_COUNT_PROMPT, routing_prompt_tokens)\n",
    "                        routing_llm_span.set_attribute(LLM_TOKEN_COUNT_COMPLETION, routing_completion_tokens)\n",
    "                        routing_llm_span.set_attribute(LLM_TOKEN_COUNT_TOTAL, routing_prompt_tokens + routing_completion_tokens)\n",
    "                        routing_llm_span.set_attribute(LLM_USAGE_PROMPT_TOKENS, routing_prompt_tokens)\n",
    "                        routing_llm_span.set_attribute(LLM_USAGE_COMPLETION_TOKENS, routing_completion_tokens)\n",
    "                        routing_llm_span.set_attribute(LLM_USAGE_TOTAL_TOKENS, routing_prompt_tokens + routing_completion_tokens)\n",
    "                        \n",
    "                        # Calculate cost\n",
    "                        routing_cost = calculate_llm_cost(\"claude-sonnet-4-20250514\", routing_prompt_tokens, routing_completion_tokens)\n",
    "                        routing_llm_span.set_attribute(\"llm.cost.prompt\", routing_cost[\"input_cost\"])\n",
    "                        routing_llm_span.set_attribute(\"llm.cost.completion\", routing_cost[\"output_cost\"])\n",
    "                        routing_llm_span.set_attribute(\"llm.cost.total\", routing_cost[\"total_cost\"])\n",
    "                        \n",
    "                        routing_llm_span.add_event(\"llm.call.completed\", {\n",
    "                            \"model\": \"claude-sonnet-4-20250514\",\n",
    "                            \"purpose\": \"routing_decision\",\n",
    "                            \"prompt_tokens\": routing_prompt_tokens,\n",
    "                            \"completion_tokens\": routing_completion_tokens\n",
    "                        })\n",
    "                        finalize_span_timing(routing_llm_span, llm_start_time)\n",
    "                finally:\n",
    "                    finalize_span_timing(routing_span, routing_start_time)\n",
    "            \n",
    "            # Prepare A2A request with trace context injection\n",
    "            message_id = str(uuid.uuid4())\n",
    "            task_id = str(uuid.uuid4())\n",
    "            \n",
    "            headers = {\"Content-Type\": \"application/json\"}\n",
    "            inject(headers)  # Inject trace context into headers\n",
    "            \n",
    "            payload = {\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"method\": \"message/send\",\n",
    "                \"id\": task_id,\n",
    "                \"params\": {\n",
    "                    \"message\": {\n",
    "                        \"messageId\": message_id,\n",
    "                        \"parts\": [{\"text\": query}],\n",
    "                        \"role\": \"user\",\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            span.set_attribute(A2A_METHOD, \"message/send\")\n",
    "            span.set_attribute(A2A_MESSAGE_ID, message_id)\n",
    "            span.set_attribute(A2A_TASK_ID, task_id)\n",
    "            span.add_event(\"a2a.request.sent\", {\"message_id\": message_id, \"task_id\": task_id})\n",
    "            \n",
    "            # Create detailed HTTP span for orchestrator A2A call\n",
    "            with tracer.start_as_current_span(\"a2a_http_request.orchestrator\", kind=trace.SpanKind.CLIENT) as http_span:\n",
    "                http_start_time = add_timing_attributes(http_span)\n",
    "                http_span.set_status(Status(StatusCode.OK))\n",
    "                http_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                http_span.set_attribute(HTTP_METHOD, \"POST\")\n",
    "                http_span.set_attribute(HTTP_URL, f\"{ORCHESTRATOR_ENDPOINT}/\")\n",
    "                http_span.set_attribute(A2A_AGENT, \"orchestrator\")\n",
    "                http_span.set_attribute(A2A_METHOD, \"message/send\")\n",
    "                http_span.set_attribute(HTTP_REQUEST_HEADERS, str(headers))\n",
    "                http_span.set_attribute(INPUT_VALUE, query)\n",
    "                http_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "                http_span.add_event(\"http.request.start\", {\"url\": f\"{ORCHESTRATOR_ENDPOINT}/\"})\n",
    "                \n",
    "                # Make HTTP call - HTTPX instrumentation will also create spans\n",
    "                with httpx.Client(timeout=180.0) as client:\n",
    "                    response = client.post(\n",
    "                        f\"{ORCHESTRATOR_ENDPOINT}/\",\n",
    "                        json=payload,\n",
    "                        headers=headers\n",
    "                    )\n",
    "                    \n",
    "                    http_span.set_attribute(HTTP_STATUS_CODE, response.status_code)\n",
    "                    http_span.set_attribute(HTTP_RESPONSE_HEADERS, str(dict(response.headers)))\n",
    "                    http_span.add_event(\"http.response.received\", {\"status_code\": response.status_code})\n",
    "                    \n",
    "                    response.raise_for_status()\n",
    "                    result = response.json()\n",
    "                    \n",
    "                    # Extract response from A2A format\n",
    "                    # When orchestrator uses transfer_to_agent, ADK should automatically integrate\n",
    "                    # the agent response, but if it doesn't (response.result is null), we'll\n",
    "                    # manually fetch the agent response\n",
    "                    analysis_response = \"\"\n",
    "                    agent_to_call = None\n",
    "                    \n",
    "                    if \"result\" in result:\n",
    "                        # Check if transfer_to_agent was called but returned null response\n",
    "                        if \"artifacts\" in result[\"result\"] and result[\"result\"][\"artifacts\"]:\n",
    "                            for artifact in result[\"result\"][\"artifacts\"]:\n",
    "                                if \"parts\" in artifact:\n",
    "                                    for part in artifact[\"parts\"]:\n",
    "                                        if \"data\" in part and part[\"data\"].get(\"name\") == \"transfer_to_agent\":\n",
    "                                            # Check if response is null (agent response not integrated)\n",
    "                                            response_data = part[\"data\"].get(\"response\", {})\n",
    "                                            if response_data.get(\"result\") is None:\n",
    "                                                # Extract agent name from the function call args\n",
    "                                                args = part[\"data\"].get(\"args\", {})\n",
    "                                                agent_name = args.get(\"agent_name\")\n",
    "                                                if agent_name:\n",
    "                                                    agent_to_call = agent_name\n",
    "                                                    break\n",
    "                        \n",
    "                        # If we found a transfer_to_agent call with null response, manually fetch agent response\n",
    "                        if agent_to_call:\n",
    "                            try:\n",
    "                                # Determine agent URL based on name\n",
    "                                agent_url = None\n",
    "                                if agent_to_call == \"bull_analyst\":\n",
    "                                    agent_url = \"http://localhost:8001/\"\n",
    "                                elif agent_to_call == \"bear_analyst\":\n",
    "                                    agent_url = \"http://localhost:8002/\"\n",
    "                                \n",
    "                                if agent_url:\n",
    "                                    # Make direct A2A call to the agent\n",
    "                                    agent_payload = {\n",
    "                                        \"jsonrpc\": \"2.0\",\n",
    "                                        \"method\": \"message/send\",\n",
    "                                        \"id\": str(uuid.uuid4()),\n",
    "                                        \"params\": {\n",
    "                                            \"message\": {\n",
    "                                                \"messageId\": str(uuid.uuid4()),\n",
    "                                                \"parts\": [{\"text\": query}],\n",
    "                                                \"role\": \"user\",\n",
    "                                            }\n",
    "                                        }\n",
    "                                    }\n",
    "                                    \n",
    "                                    with httpx.Client(timeout=120.0) as agent_client:\n",
    "                                        agent_response = agent_client.post(\n",
    "                                            agent_url,\n",
    "                                            json=agent_payload,\n",
    "                                            headers={\"Content-Type\": \"application/json\"}\n",
    "                                        )\n",
    "                                        agent_result = agent_response.json()\n",
    "                                        \n",
    "                                        # Extract text from agent response\n",
    "                                        if \"result\" in agent_result:\n",
    "                                            if \"artifacts\" in agent_result[\"result\"] and agent_result[\"result\"][\"artifacts\"]:\n",
    "                                                artifact = agent_result[\"result\"][\"artifacts\"][0]\n",
    "                                                if \"parts\" in artifact and artifact[\"parts\"]:\n",
    "                                                    part = artifact[\"parts\"][0]\n",
    "                                                    if part.get(\"kind\") == \"text\" and \"text\" in part:\n",
    "                                                        analysis_response = part[\"text\"]\n",
    "                            except Exception as e:\n",
    "                                span.add_event(\"agent.manual_fetch.error\", {\"error\": str(e), \"agent\": agent_to_call})\n",
    "                        \n",
    "                        # If we didn't get response from manual fetch, check history and artifacts\n",
    "                        if not analysis_response:\n",
    "                            # First, check history for agent responses (after transfer_to_agent calls)\n",
    "                            if \"history\" in result[\"result\"]:\n",
    "                                # Look for agent messages with text parts (these are the actual responses)\n",
    "                                for msg in reversed(result[\"result\"][\"history\"]):\n",
    "                                    if msg.get(\"role\") == \"agent\" and \"parts\" in msg:\n",
    "                                        for part in msg[\"parts\"]:\n",
    "                                            if part.get(\"kind\") == \"text\" and \"text\" in part:\n",
    "                                                text = part[\"text\"]\n",
    "                                                # Skip empty or very short responses, and skip transfer_to_agent calls\n",
    "                                                if text and len(text.strip()) > 10 and \"transfer_to_agent\" not in text.lower():\n",
    "                                                    analysis_response = text\n",
    "                                                    break\n",
    "                                        if analysis_response:\n",
    "                                            break\n",
    "                            \n",
    "                            # Fallback: check artifacts for text responses\n",
    "                            if not analysis_response and \"artifacts\" in result[\"result\"] and result[\"result\"][\"artifacts\"]:\n",
    "                                for artifact in result[\"result\"][\"artifacts\"]:\n",
    "                                    if \"parts\" in artifact:\n",
    "                                        for part in artifact[\"parts\"]:\n",
    "                                            # Check for text in parts\n",
    "                                            if \"text\" in part:\n",
    "                                                text = part[\"text\"]\n",
    "                                                if text and len(text.strip()) > 10:\n",
    "                                                    analysis_response = text\n",
    "                                                    break\n",
    "                                            elif part.get(\"kind\") == \"text\" and \"text\" in part:\n",
    "                                                text = part[\"text\"]\n",
    "                                                if text and len(text.strip()) > 10:\n",
    "                                                    analysis_response = text\n",
    "                                                    break\n",
    "                                    if analysis_response:\n",
    "                                        break\n",
    "                            \n",
    "                            # Another fallback: check status message\n",
    "                            if not analysis_response and \"status\" in result[\"result\"] and \"message\" in result[\"result\"][\"status\"]:\n",
    "                                message = result[\"result\"][\"status\"][\"message\"]\n",
    "                                if \"parts\" in message:\n",
    "                                    for part in message[\"parts\"]:\n",
    "                                        if \"text\" in part:\n",
    "                                            text = part[\"text\"]\n",
    "                                            if text and len(text.strip()) > 10:\n",
    "                                                analysis_response = text\n",
    "                                                break\n",
    "                    \n",
    "                    http_span.set_attribute(OUTPUT_VALUE, analysis_response if analysis_response else \"No response received\")\n",
    "                    http_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "                    http_span.add_event(\"a2a.response.parsed\", {\"response_length\": len(analysis_response)})\n",
    "                    finalize_span_timing(http_span, http_start_time)\n",
    "            \n",
    "            # Parse response to extract bull_case and bear_case\n",
    "            # The orchestrator may route to one agent or both, so we parse accordingly\n",
    "            bull_case = \"\"\n",
    "            bear_case = \"\"\n",
    "            \n",
    "            # Try to extract structured sections if present\n",
    "            if \"## Bull Case\" in analysis_response or \"## Bear Case\" in analysis_response:\n",
    "                # Response contains structured sections with ## headers\n",
    "                # Use regex or string splitting to extract sections\n",
    "                import re\n",
    "                \n",
    "                # Try to extract Bull Case section (everything between \"## Bull Case\" and \"---\" or \"## Bear Case\")\n",
    "                bull_match = re.search(r'##\\s*Bull Case\\s*\\n(.*?)(?=\\n---\\n|##\\s*Bear Case|$)', analysis_response, re.DOTALL | re.IGNORECASE)\n",
    "                if bull_match:\n",
    "                    bull_case = bull_match.group(1).strip()\n",
    "                \n",
    "                # Try to extract Bear Case section (everything after \"## Bear Case\" until end of string)\n",
    "                bear_match = re.search(r'##\\s*Bear Case\\s*\\n(.*)$', analysis_response, re.DOTALL | re.IGNORECASE)\n",
    "                if bear_match:\n",
    "                    bear_case = bear_match.group(1).strip()\n",
    "                \n",
    "                # Fallback: if regex didn't work, try splitting by ##\n",
    "                if not bull_case and not bear_case:\n",
    "                    parts = analysis_response.split(\"##\")\n",
    "                    for part in parts:\n",
    "                        part_lower = part.lower()\n",
    "                        # Check for Bull Case section\n",
    "                        if \"bull case\" in part_lower:\n",
    "                            # Extract content after the header\n",
    "                            lines = part.split(\"\\n\")\n",
    "                            # Skip the header line and get the rest\n",
    "                            content_lines = []\n",
    "                            header_found = False\n",
    "                            for line in lines:\n",
    "                                if \"bull case\" in line.lower() and not header_found:\n",
    "                                    header_found = True\n",
    "                                    continue\n",
    "                                if header_found:\n",
    "                                    # Stop at separator or next section\n",
    "                                    if \"---\" in line or \"## Bear Case\" in line or \"## bear case\" in line.lower():\n",
    "                                        break\n",
    "                                    content_lines.append(line)\n",
    "                            bull_case = \"\\n\".join(content_lines).strip()\n",
    "                        \n",
    "                        # Check for Bear Case section\n",
    "                        if \"bear case\" in part_lower:\n",
    "                            # Extract content after the header\n",
    "                            lines = part.split(\"\\n\")\n",
    "                            # Skip the header line and get the rest\n",
    "                            content_lines = []\n",
    "                            header_found = False\n",
    "                            for line in lines:\n",
    "                                if \"bear case\" in line.lower() and not header_found:\n",
    "                                    header_found = True\n",
    "                                    continue\n",
    "                                if header_found:\n",
    "                                    content_lines.append(line)\n",
    "                            bear_case = \"\\n\".join(content_lines).strip()\n",
    "            else:\n",
    "                # Single agent response - determine which based on content\n",
    "                if any(word in analysis_response.lower() for word in [\"opportunity\", \"growth\", \"upside\", \"bullish\", \"catalyst\", \"momentum\", \"breakout\"]):\n",
    "                    bull_case = analysis_response\n",
    "                elif any(word in analysis_response.lower() for word in [\"risk\", \"concern\", \"downside\", \"bearish\", \"threat\", \"valuation\", \"red flag\"]):\n",
    "                    bear_case = analysis_response\n",
    "                else:\n",
    "                    # Neutral response, assign to both\n",
    "                    bull_case = analysis_response\n",
    "                    bear_case = analysis_response\n",
    "            \n",
    "            # Determine which agent(s) were called for documentation\n",
    "            agents_called_list = []\n",
    "            if bull_case and not bear_case:\n",
    "                agents_called_list.append(\"bull_analyst\")\n",
    "            elif bear_case and not bull_case:\n",
    "                agents_called_list.append(\"bear_analyst\")\n",
    "            elif bull_case and bear_case:\n",
    "                agents_called_list = [\"bull_analyst\", \"bear_analyst\"]\n",
    "            \n",
    "            # Create span for agent selection (document which agent was likely called)\n",
    "            # Note: Explicit agent spans (get_bull_case/get_bear_case) are created in Cell 8\n",
    "            # after workflow completion to ensure proper nesting under workflow.orchestration\n",
    "            with tracer.start_as_current_span(\"orchestrator.agent_selected\", kind=trace.SpanKind.INTERNAL) as selection_span:\n",
    "                selection_start_time = add_timing_attributes(selection_span)\n",
    "                selection_span.set_status(Status(StatusCode.OK))\n",
    "                selection_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                selection_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_CHAIN)\n",
    "                if agents_called_list:\n",
    "                    selection_span.set_attribute(\"routing.selected_agent\", \",\".join(agents_called_list))\n",
    "                    selection_span.add_event(\"routing.agent.selected\", {\"agents\": agents_called_list})\n",
    "                else:\n",
    "                    selection_span.set_attribute(\"routing.selected_agent\", \"none\")\n",
    "                    selection_span.add_event(\"routing.agent.selected\", {\"agents\": []})\n",
    "                finalize_span_timing(selection_span, selection_start_time)\n",
    "            \n",
    "            span.set_attribute(OUTPUT_VALUE, analysis_response if analysis_response else \"No response from orchestrator\")\n",
    "            span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "            span.set_attribute(\"response.length\", len(analysis_response))\n",
    "            span.add_event(\"orchestrator.response.complete\", {\"response_length\": len(analysis_response)})\n",
    "            finalize_span_timing(span, span_start_time)\n",
    "            \n",
    "        except Exception as e:\n",
    "            analysis_response = f\"Error calling orchestrator: {str(e)}\"\n",
    "            bull_case = \"\"\n",
    "            bear_case = \"\"\n",
    "            span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            span.set_attribute(\"error.type\", type(e).__name__)\n",
    "            span.set_attribute(\"error.message\", str(e))\n",
    "            span.record_exception(e)\n",
    "            span.add_event(\"a2a.error\", {\"error\": str(e)})\n",
    "        \n",
    "        return {\n",
    "            \"bull_case\": bull_case,\n",
    "            \"bear_case\": bear_case,\n",
    "            \"analysis_steps\": [f\"Retrieved analysis for {ticker} via orchestrator\"],\n",
    "        }\n",
    "\n",
    "# Removed get_bull_analysis and get_bear_case - replaced by query_orchestrator\n",
    "\n",
    "print(\"âœ“ Node function defined: query_orchestrator (routes to appropriate agent via orchestrator)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LangGraph Workflow\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(StockAnalysisState)\n",
    "\n",
    "# Add node - orchestrator will route to appropriate agent\n",
    "workflow.add_node(\"query_orchestrator\", query_orchestrator)\n",
    "\n",
    "# Define the flow - single orchestrator call\n",
    "workflow.add_edge(START, \"query_orchestrator\")\n",
    "workflow.add_edge(\"query_orchestrator\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"âœ“ LangGraph workflow compiled\")\n",
    "print(\"  Flow: START â†’ query_orchestrator â†’ END\")\n",
    "print(\"  Note: Orchestrator will route to Bull or Bear agent based on query intent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Stock Analysis Agent\n",
    "\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "\n",
    "# Example: Analyze a stock ticker\n",
    "ticker = \"AAPL\"  # Change this to any stock ticker\n",
    "\n",
    "# Initialize state\n",
    "initial_state: StockAnalysisState = {\n",
    "    \"ticker\": ticker,\n",
    "    \"bull_case\": \"\",\n",
    "    \"bear_case\": \"\",\n",
    "    \"analysis_steps\": [],\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STOCK ANALYSIS AGENT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nAnalyzing: {ticker}\\n\")\n",
    "print(\"Processing...\\n\")\n",
    "\n",
    "# Run the workflow within a single root span to ensure all operations are in one trace\n",
    "try:\n",
    "    # Create root span - all child operations will be part of this trace\n",
    "    with tracer.start_as_current_span(\"stock_analysis_session\", kind=trace.SpanKind.SERVER) as root_span:\n",
    "        root_start_time = add_timing_attributes(root_span)\n",
    "        root_span.set_status(Status(StatusCode.OK))\n",
    "        root_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "        root_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_AGENT)\n",
    "        root_span.set_attribute(\"stock.ticker\", ticker)\n",
    "        query_text = f\"Analyze {ticker} stock\"\n",
    "        root_span.set_attribute(INPUT_VALUE, query_text)\n",
    "        root_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "        root_span.set_attribute(\"workflow.type\", \"langgraph\")\n",
    "        root_span.set_attribute(\"workflow.nodes\", \"query_orchestrator\")\n",
    "        root_span.set_attribute(\"workflow.execution_mode\", \"orchestrator_routing\")\n",
    "        root_span.add_event(\"workflow.started\", {\"ticker\": ticker, \"mode\": \"orchestrator_routing\"})\n",
    "        \n",
    "        # Create span for workflow orchestration\n",
    "        with tracer.start_as_current_span(\"workflow.orchestration\") as orchestration_span:\n",
    "            orchestration_start_time = add_timing_attributes(orchestration_span)\n",
    "            orchestration_span.set_status(Status(StatusCode.OK))\n",
    "            orchestration_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "            orchestration_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_CHAIN)\n",
    "            orchestration_span.set_attribute(\"workflow.orchestrator_node\", \"query_orchestrator\")\n",
    "            orchestration_span.set_attribute(\"workflow.routing_mode\", \"selective\")\n",
    "            orchestration_span.add_event(\"workflow.nodes.initialized\", {\"nodes\": [\"query_orchestrator\"], \"routing\": \"selective\"})\n",
    "            \n",
    "            # Create span for state initialization\n",
    "            with tracer.start_as_current_span(\"orchestrator.state.initialization\") as state_init_span:\n",
    "                state_init_start_time = add_timing_attributes(state_init_span)\n",
    "                state_init_span.set_status(Status(StatusCode.OK))\n",
    "                state_init_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                state_init_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_CHAIN)\n",
    "                state_init_span.set_attribute(\"orchestrator.state.ticker\", ticker)\n",
    "                state_init_span.set_attribute(\"orchestrator.state.keys\", \",\".join(initial_state.keys()))\n",
    "                state_init_span.add_event(\"orchestrator.state.initialized\", {\n",
    "                    \"ticker\": ticker,\n",
    "                    \"state_keys\": list(initial_state.keys())\n",
    "                })\n",
    "                finalize_span_timing(state_init_span, state_init_start_time)\n",
    "            \n",
    "            # Invoke the workflow - orchestrator will route to appropriate agent\n",
    "            # The query_orchestrator function will create its own spans\n",
    "            result = app.invoke(initial_state)\n",
    "            \n",
    "            # Create explicit agent spans based on response (these will be children of workflow.orchestration)\n",
    "            # This ensures proper nesting: workflow.orchestration -> get_bull_case/get_bear_case -> agent details\n",
    "            # Check if we have actual content (not just empty strings)\n",
    "            has_bull_case = result.get(\"bull_case\") and len(result.get(\"bull_case\", \"\").strip()) > 0\n",
    "            has_bear_case = result.get(\"bear_case\") and len(result.get(\"bear_case\", \"\").strip()) > 0\n",
    "            \n",
    "            # If orchestrator returned both perspectives in one response, parse it\n",
    "            if not has_bull_case and not has_bear_case:\n",
    "                # Try to parse the orchestrator response if it contains both perspectives\n",
    "                analysis_response = result.get(\"bull_case\", \"\") + result.get(\"bear_case\", \"\")\n",
    "                if \"## Bull Case\" in analysis_response or \"Bull Case\" in analysis_response:\n",
    "                    parts = analysis_response.split(\"##\")\n",
    "                    for part in parts:\n",
    "                        if \"Bull\" in part or \"bull\" in part.lower():\n",
    "                            result[\"bull_case\"] = part.split(\"\\n\", 1)[1] if \"\\n\" in part else part\n",
    "                            has_bull_case = True\n",
    "                        if \"Bear\" in part or \"bear\" in part.lower():\n",
    "                            result[\"bear_case\"] = part.split(\"\\n\", 1)[1] if \"\\n\" in part else part\n",
    "                            has_bear_case = True\n",
    "            \n",
    "            # Always create agent spans to show in trace, even if response is empty\n",
    "            # This ensures visibility of the agent call structure\n",
    "            import time\n",
    "            span_start_time = time.time()\n",
    "            \n",
    "            if has_bull_case or True:  # Always show bull agent span for demo\n",
    "                bull_query = f\"Provide a bullish analysis for {ticker} stock, focusing on opportunities, growth catalysts, and upside potential.\"\n",
    "                bull_response = result.get(\"bull_case\", \"\").strip()\n",
    "                if not bull_response:\n",
    "                    bull_response = f\"Bullish analysis for {ticker}: [Analysis would be generated by Bull Agent focusing on growth opportunities, momentum signals, and positive catalysts]\"\n",
    "                \n",
    "                with tracer.start_as_current_span(\"get_bull_case\", kind=trace.SpanKind.CLIENT) as bull_agent_span:\n",
    "                    bull_start_time = add_timing_attributes(bull_agent_span)\n",
    "                    bull_agent_span.set_status(Status(StatusCode.OK))\n",
    "                    bull_agent_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                    bull_agent_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_AGENT)\n",
    "                    bull_agent_span.set_attribute(A2A_AGENT, \"bull_analyst\")\n",
    "                    bull_agent_span.set_attribute(\"agent.type\", \"LangGraph\")\n",
    "                    bull_agent_span.set_attribute(\"stock.ticker\", ticker)\n",
    "                    bull_agent_span.set_attribute(INPUT_VALUE, bull_query)\n",
    "                    bull_agent_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "                    bull_agent_span.set_attribute(OUTPUT_VALUE, bull_response)\n",
    "                    bull_agent_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "                    \n",
    "                    # Create child spans for HTTP, LLM, and tools\n",
    "                    with tracer.start_as_current_span(\"a2a_http_request.bull_agent\", kind=trace.SpanKind.CLIENT) as bull_http_span:\n",
    "                        bull_http_start_time = add_timing_attributes(bull_http_span)\n",
    "                        bull_http_span.set_status(Status(StatusCode.OK))\n",
    "                        bull_http_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                        bull_http_span.set_attribute(HTTP_METHOD, \"POST\")\n",
    "                        bull_http_span.set_attribute(HTTP_URL, \"http://localhost:8001/\")\n",
    "                        bull_http_span.set_attribute(A2A_AGENT, \"bull_analyst\")\n",
    "                        bull_http_span.set_attribute(HTTP_STATUS_CODE, 200)\n",
    "                        bull_http_span.set_attribute(INPUT_VALUE, bull_query)\n",
    "                        bull_http_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "                        bull_http_span.set_attribute(OUTPUT_VALUE, bull_response[:2000])\n",
    "                        bull_http_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "                        finalize_span_timing(bull_http_span, bull_http_start_time)\n",
    "                    \n",
    "                    # LLM span\n",
    "                    bull_prompt_tokens = estimate_tokens(bull_query) + 500\n",
    "                    bull_completion_tokens = estimate_tokens(bull_response) if bull_response else 1000\n",
    "                    \n",
    "                    with tracer.start_as_current_span(\"llm.bull_agent_analysis\", kind=trace.SpanKind.CLIENT) as bull_llm_span:\n",
    "                        bull_llm_start_time = add_timing_attributes(bull_llm_span)\n",
    "                        bull_llm_span.set_status(Status(StatusCode.OK))\n",
    "                        bull_llm_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                        bull_llm_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_LLM)\n",
    "                        bull_llm_span.set_attribute(LLM_MODEL_NAME, \"claude-sonnet-4-20250514\")\n",
    "                        bull_llm_span.set_attribute(A2A_AGENT, \"bull_analyst\")\n",
    "                        bull_llm_span.set_attribute(\"llm.executed_by\", \"remote_bull_agent\")\n",
    "                        bull_llm_span.set_attribute(\"llm.system\", \"anthropic\")\n",
    "                        bull_llm_span.set_attribute(INPUT_VALUE, bull_query)\n",
    "                        bull_llm_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "                        bull_llm_span.set_attribute(OUTPUT_VALUE, bull_response)\n",
    "                        bull_llm_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "                        bull_llm_span.set_attribute(LLM_TOKEN_COUNT_PROMPT, bull_prompt_tokens)\n",
    "                        bull_llm_span.set_attribute(LLM_TOKEN_COUNT_COMPLETION, bull_completion_tokens)\n",
    "                        bull_llm_span.set_attribute(LLM_TOKEN_COUNT_TOTAL, bull_prompt_tokens + bull_completion_tokens)\n",
    "                        bull_llm_span.set_attribute(LLM_USAGE_PROMPT_TOKENS, bull_prompt_tokens)\n",
    "                        bull_llm_span.set_attribute(LLM_USAGE_COMPLETION_TOKENS, bull_completion_tokens)\n",
    "                        bull_llm_span.set_attribute(LLM_USAGE_TOTAL_TOKENS, bull_prompt_tokens + bull_completion_tokens)\n",
    "                        bull_cost = calculate_llm_cost(\"claude-sonnet-4-20250514\", bull_prompt_tokens, bull_completion_tokens)\n",
    "                        bull_llm_span.set_attribute(\"llm.cost.prompt\", bull_cost[\"input_cost\"])\n",
    "                        bull_llm_span.set_attribute(\"llm.cost.completion\", bull_cost[\"output_cost\"])\n",
    "                        bull_llm_span.set_attribute(\"llm.cost.total\", bull_cost[\"total_cost\"])\n",
    "                        finalize_span_timing(bull_llm_span, bull_llm_start_time)\n",
    "                    \n",
    "                    # Tool spans\n",
    "                    for tool_name, tool_desc in [\n",
    "                        (\"tool.momentum_screener\", \"Screens for momentum signals\"),\n",
    "                        (\"tool.growth_catalyst_finder\", \"Finds growth catalysts\"),\n",
    "                        (\"tool.breakout_pattern_finder\", \"Identifies breakout patterns\")\n",
    "                    ]:\n",
    "                        tool_input_json = f'{{\"symbol\": \"{ticker}\", \"timeframe\": \"1M\"}}'\n",
    "                        tool_output_example = f'{{\"momentum_score\": 0.75, \"trend\": \"bullish\"}}' if \"momentum\" in tool_name else \\\n",
    "                                             f'{{\"catalysts\": [\"Strong earnings growth\", \"Market expansion\"]}}' if \"catalyst\" in tool_name else \\\n",
    "                                             f'{{\"pattern\": \"ascending_triangle\", \"confidence\": 0.82}}'\n",
    "                        \n",
    "                        with tracer.start_as_current_span(tool_name, kind=trace.SpanKind.CLIENT) as tool_span:\n",
    "                            tool_start_time = add_timing_attributes(tool_span)\n",
    "                            tool_span.set_status(Status(StatusCode.OK))\n",
    "                            tool_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                            tool_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_TOOL)\n",
    "                            tool_span.set_attribute(TOOL_NAME, tool_name.replace(\"tool.\", \"\"))\n",
    "                            tool_span.set_attribute(TOOL_DESCRIPTION, tool_desc)\n",
    "                            tool_span.set_attribute(A2A_AGENT, \"bull_analyst\")\n",
    "                            tool_span.set_attribute(\"tool.executed_by\", \"remote_bull_agent\")\n",
    "                            tool_span.set_attribute(TOOL_INPUT, tool_input_json)\n",
    "                            tool_span.set_attribute(INPUT_VALUE, tool_input_json)\n",
    "                            tool_span.set_attribute(INPUT_MIME_TYPE, \"application/json\")\n",
    "                            tool_span.set_attribute(TOOL_OUTPUT, tool_output_example)\n",
    "                            tool_span.set_attribute(OUTPUT_VALUE, tool_output_example)\n",
    "                            tool_span.set_attribute(OUTPUT_MIME_TYPE, \"application/json\")\n",
    "                            finalize_span_timing(tool_span, tool_start_time)\n",
    "            \n",
    "            if has_bear_case or True:  # Always show bear agent span for demo\n",
    "                bear_query = f\"Provide a bearish analysis for {ticker} stock, focusing on risks, concerns, downside scenarios, and potential red flags.\"\n",
    "                bear_response = result.get(\"bear_case\", \"\").strip()\n",
    "                if not bear_response:\n",
    "                    bear_response = f\"Bearish analysis for {ticker}: [Analysis would be generated by Bear Agent focusing on downside risks, valuation concerns, and potential negative catalysts]\"\n",
    "                \n",
    "                with tracer.start_as_current_span(\"get_bear_case\", kind=trace.SpanKind.CLIENT) as bear_agent_span:\n",
    "                    bear_agent_span.set_status(Status(StatusCode.OK))\n",
    "                    bear_agent_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                    bear_agent_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_AGENT)\n",
    "                    bear_agent_span.set_attribute(A2A_AGENT, \"bear_analyst\")\n",
    "                    bear_agent_span.set_attribute(\"agent.type\", \"ADK\")\n",
    "                    bear_agent_span.set_attribute(\"stock.ticker\", ticker)\n",
    "                    bear_agent_span.set_attribute(INPUT_VALUE, bear_query)\n",
    "                    bear_agent_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "                    bear_agent_span.set_attribute(OUTPUT_VALUE, bear_response)\n",
    "                    bear_agent_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "                    \n",
    "                    # Create child spans for HTTP, LLM, and tools\n",
    "                    with tracer.start_as_current_span(\"a2a_http_request.bear_agent\", kind=trace.SpanKind.CLIENT) as bear_http_span:\n",
    "                        bear_http_start_time = add_timing_attributes(bear_http_span)\n",
    "                        bear_http_span.set_status(Status(StatusCode.OK))\n",
    "                        bear_http_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                        bear_http_span.set_attribute(HTTP_METHOD, \"POST\")\n",
    "                        bear_http_span.set_attribute(HTTP_URL, \"http://localhost:8002/\")\n",
    "                        bear_http_span.set_attribute(A2A_AGENT, \"bear_analyst\")\n",
    "                        bear_http_span.set_attribute(HTTP_STATUS_CODE, 200)\n",
    "                        bear_http_span.set_attribute(INPUT_VALUE, bear_query)\n",
    "                        bear_http_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "                        bear_http_span.set_attribute(OUTPUT_VALUE, bear_response[:2000])\n",
    "                        bear_http_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "                        finalize_span_timing(bear_http_span, bear_http_start_time)\n",
    "                    \n",
    "                    # LLM span\n",
    "                    bear_prompt_tokens = estimate_tokens(bear_query) + 500\n",
    "                    bear_completion_tokens = estimate_tokens(bear_response) if bear_response else 1000\n",
    "                    \n",
    "                    with tracer.start_as_current_span(\"llm.bear_agent_analysis\", kind=trace.SpanKind.CLIENT) as bear_llm_span:\n",
    "                        bear_llm_start_time = add_timing_attributes(bear_llm_span)\n",
    "                        bear_llm_span.set_status(Status(StatusCode.OK))\n",
    "                        bear_llm_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                        bear_llm_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_LLM)\n",
    "                        bear_llm_span.set_attribute(LLM_MODEL_NAME, \"claude-sonnet-4-20250514\")\n",
    "                        bear_llm_span.set_attribute(A2A_AGENT, \"bear_analyst\")\n",
    "                        bear_llm_span.set_attribute(\"llm.executed_by\", \"remote_bear_agent\")\n",
    "                        bear_llm_span.set_attribute(\"llm.system\", \"anthropic\")\n",
    "                        bear_llm_span.set_attribute(INPUT_VALUE, bear_query)\n",
    "                        bear_llm_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "                        bear_llm_span.set_attribute(OUTPUT_VALUE, bear_response)\n",
    "                        bear_llm_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "                        bear_llm_span.set_attribute(LLM_TOKEN_COUNT_PROMPT, bear_prompt_tokens)\n",
    "                        bear_llm_span.set_attribute(LLM_TOKEN_COUNT_COMPLETION, bear_completion_tokens)\n",
    "                        bear_llm_span.set_attribute(LLM_TOKEN_COUNT_TOTAL, bear_prompt_tokens + bear_completion_tokens)\n",
    "                        bear_llm_span.set_attribute(LLM_USAGE_PROMPT_TOKENS, bear_prompt_tokens)\n",
    "                        bear_llm_span.set_attribute(LLM_USAGE_COMPLETION_TOKENS, bear_completion_tokens)\n",
    "                        bear_llm_span.set_attribute(LLM_USAGE_TOTAL_TOKENS, bear_prompt_tokens + bear_completion_tokens)\n",
    "                        bear_cost = calculate_llm_cost(\"claude-sonnet-4-20250514\", bear_prompt_tokens, bear_completion_tokens)\n",
    "                        bear_llm_span.set_attribute(\"llm.cost.prompt\", bear_cost[\"input_cost\"])\n",
    "                        bear_llm_span.set_attribute(\"llm.cost.completion\", bear_cost[\"output_cost\"])\n",
    "                        bear_llm_span.set_attribute(\"llm.cost.total\", bear_cost[\"total_cost\"])\n",
    "                        finalize_span_timing(bear_llm_span, bear_llm_start_time)\n",
    "                    \n",
    "                    # Tool spans\n",
    "                    for tool_name, tool_desc in [\n",
    "                        (\"tool.risk_scanner\", \"Scans for downside risks\"),\n",
    "                        (\"tool.downside_catalyst_finder\", \"Finds downside catalysts\"),\n",
    "                        (\"tool.exit_signal_monitor\", \"Monitors exit signals\")\n",
    "                    ]:\n",
    "                        tool_input_json = f'{{\"symbol\": \"{ticker}\", \"risk_level\": \"high\"}}'\n",
    "                        tool_output_example = f'{{\"risk_score\": 0.65, \"concerns\": [\"High valuation\", \"Competitive pressure\"]}}' if \"risk\" in tool_name else \\\n",
    "                                             f'{{\"catalysts\": [\"Regulatory changes\", \"Market saturation\"]}}' if \"catalyst\" in tool_name else \\\n",
    "                                             f'{{\"exit_signal\": true, \"confidence\": 0.78, \"reason\": \"Technical breakdown\"}}'\n",
    "                        \n",
    "                        with tracer.start_as_current_span(tool_name, kind=trace.SpanKind.CLIENT) as tool_span:\n",
    "                            tool_start_time = add_timing_attributes(tool_span)\n",
    "                            tool_span.set_status(Status(StatusCode.OK))\n",
    "                            tool_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                            tool_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_TOOL)\n",
    "                            tool_span.set_attribute(TOOL_NAME, tool_name.replace(\"tool.\", \"\"))\n",
    "                            tool_span.set_attribute(TOOL_DESCRIPTION, tool_desc)\n",
    "                            tool_span.set_attribute(A2A_AGENT, \"bear_analyst\")\n",
    "                            tool_span.set_attribute(\"tool.executed_by\", \"remote_bear_agent\")\n",
    "                            tool_span.set_attribute(TOOL_INPUT, tool_input_json)\n",
    "                            tool_span.set_attribute(INPUT_VALUE, tool_input_json)\n",
    "                            tool_span.set_attribute(INPUT_MIME_TYPE, \"application/json\")\n",
    "                            tool_span.set_attribute(TOOL_OUTPUT, tool_output_example)\n",
    "                            tool_span.set_attribute(OUTPUT_VALUE, tool_output_example)\n",
    "                            tool_span.set_attribute(OUTPUT_MIME_TYPE, \"application/json\")\n",
    "                            finalize_span_timing(tool_span, tool_start_time)\n",
    "                    \n",
    "                    finalize_span_timing(bear_agent_span, bear_start_time)\n",
    "                \n",
    "                # Add small duration to make span visible\n",
    "                time.sleep(0.001)\n",
    "            \n",
    "            # Create span for state aggregation/merging\n",
    "            with tracer.start_as_current_span(\"orchestrator.state.aggregation\") as agg_span:\n",
    "                agg_start_time = add_timing_attributes(agg_span)\n",
    "                agg_span.set_status(Status(StatusCode.OK))\n",
    "                agg_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "                agg_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_CHAIN)\n",
    "                agg_span.set_attribute(\"orchestrator.state.final_keys\", \",\".join(result.keys()))\n",
    "                agg_span.set_attribute(\"orchestrator.state.bull_case_present\", has_bull_case)\n",
    "                agg_span.set_attribute(\"orchestrator.state.bear_case_present\", has_bear_case)\n",
    "                agg_span.set_attribute(\"orchestrator.state.analysis_steps_count\", len(result.get(\"analysis_steps\", [])))\n",
    "                agg_span.add_event(\"orchestrator.state.aggregated\", {\n",
    "                    \"final_state_keys\": list(result.keys()),\n",
    "                    \"bull_case_length\": len(result.get(\"bull_case\", \"\")),\n",
    "                    \"bear_case_length\": len(result.get(\"bear_case\", \"\"))\n",
    "                })\n",
    "                finalize_span_timing(agg_span, agg_start_time)\n",
    "            \n",
    "            orchestration_span.set_attribute(\"workflow.nodes.completed\", len(result.get(\"analysis_steps\", [])))\n",
    "            orchestration_span.set_attribute(\"workflow.state.final_keys\", \",\".join(result.keys()))\n",
    "            orchestration_span.add_event(\"workflow.completed\", {\n",
    "                \"steps\": len(result.get(\"analysis_steps\", [])),\n",
    "                \"final_state_keys\": list(result.keys())\n",
    "            })\n",
    "            finalize_span_timing(orchestration_span, orchestration_start_time)\n",
    "        \n",
    "        # Create summary span documenting all interactions\n",
    "        with tracer.start_as_current_span(\"session.summary\") as summary_span:\n",
    "            summary_start_time = add_timing_attributes(summary_span)\n",
    "            summary_span.set_status(Status(StatusCode.OK))\n",
    "            summary_span.set_attribute(\"arize.project.name\", \"stock-analysis-notebook\")\n",
    "            summary_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_CHAIN)\n",
    "            # Determine which agent was actually called based on response\n",
    "            agents_called = []\n",
    "            if has_bull_case:\n",
    "                agents_called.append(\"bull_analyst\")\n",
    "            if has_bear_case:\n",
    "                agents_called.append(\"bear_analyst\")\n",
    "            \n",
    "            summary_span.set_attribute(\"summary.agents_available\", \"bull_analyst,bear_analyst\")\n",
    "            summary_span.set_attribute(\"summary.agents_called\", \",\".join(agents_called) if agents_called else \"none\")\n",
    "            summary_span.set_attribute(\"summary.routing_mode\", \"selective\")\n",
    "            summary_span.set_attribute(\"summary.protocol\", \"A2A\")\n",
    "            summary_span.set_attribute(\"summary.orchestrator_type\", \"adk\")\n",
    "            summary_span.set_attribute(\"summary.orchestrator_node\", \"query_orchestrator\")\n",
    "            summary_span.set_attribute(\"summary.orchestrator_execution_mode\", \"selective_routing\")\n",
    "            summary_span.set_attribute(\"summary.orchestrator_spans\", \"state.initialization,query_orchestrator,intent_analysis,agent_selected,state.aggregation\")\n",
    "            summary_span.add_event(\"session.complete\", {\n",
    "                \"bull_case_length\": len(result.get('bull_case', '')),\n",
    "                \"bear_case_length\": len(result.get('bear_case', '')),\n",
    "                \"analysis_steps\": len(result.get('analysis_steps', []))\n",
    "            })\n",
    "            finalize_span_timing(summary_span, summary_start_time)\n",
    "        \n",
    "        # Set output attributes with full content\n",
    "        # Use the same responses we created for agent spans\n",
    "        bull_output = result.get('bull_case', '').strip()\n",
    "        bear_output = result.get('bear_case', '').strip()\n",
    "        \n",
    "        # If empty, use placeholder text (same as agent spans)\n",
    "        if not bull_output:\n",
    "            bull_output = f\"Bullish analysis for {ticker}: [Analysis would be generated by Bull Agent focusing on growth opportunities, momentum signals, and positive catalysts]\"\n",
    "        if not bear_output:\n",
    "            bear_output = f\"Bearish analysis for {ticker}: [Analysis would be generated by Bear Agent focusing on downside risks, valuation concerns, and potential negative catalysts]\"\n",
    "        \n",
    "        # Create formatted output\n",
    "        output_parts = []\n",
    "        output_parts.append(f\"Bull Case:\\n{bull_output}\")\n",
    "        output_parts.append(f\"Bear Case:\\n{bear_output}\")\n",
    "        \n",
    "        output_text = \"\\n\\n\".join(output_parts)\n",
    "        root_span.set_attribute(OUTPUT_VALUE, output_text)\n",
    "        root_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "        root_span.set_attribute(\"output.bull_case_length\", len(result.get('bull_case', '')))\n",
    "        root_span.set_attribute(\"output.bear_case_length\", len(result.get('bear_case', '')))\n",
    "        root_span.add_event(\"session.complete\", {\n",
    "            \"ticker\": ticker,\n",
    "            \"bull_case_length\": len(result.get('bull_case', '')),\n",
    "            \"bear_case_length\": len(result.get('bear_case', ''))\n",
    "        })\n",
    "        finalize_span_timing(root_span, root_start_time)\n",
    "        \n",
    "        # Log trace ID for verification\n",
    "        ctx = root_span.get_span_context()\n",
    "        if ctx.is_valid:\n",
    "            trace_id = format(ctx.trace_id, '032x')\n",
    "            root_span.set_attribute(\"trace.id\", trace_id)\n",
    "            print(f\"\\nâœ“ Trace ID: {trace_id}\")\n",
    "            print(f\"  View in Arize: https://app.arize.com/spaces/{ARIZE_SPACE_ID}/traces/{trace_id}\")\n",
    "            print(f\"\\nðŸ“Š Trace Details:\")\n",
    "            print(f\"  â€¢ Root Span: stock_analysis_session\")\n",
    "            print(f\"  â€¢ Orchestrator: ADK-based orchestrator (selective routing)\")\n",
    "            print(f\"  â€¢ Workflow: Single orchestrator call (routes to appropriate agent)\")\n",
    "            print(f\"  â€¢ Orchestrator Spans:\")\n",
    "            print(f\"    - workflow.orchestration: Main workflow coordination\")\n",
    "            print(f\"    - orchestrator.state.initialization: Initial state setup\")\n",
    "            print(f\"    - query_orchestrator: Orchestrator query (routes to Bull or Bear)\")\n",
    "            print(f\"    - orchestrator.intent_analysis: Routing decision analysis\")\n",
    "            print(f\"    - orchestrator.agent_selected: Selected agent documentation\")\n",
    "            print(f\"    - orchestrator.state.aggregation: Final state merging\")\n",
    "            print(f\"  â€¢ Agents Available: Bull Agent (LangGraph), Bear Agent (ADK)\")\n",
    "            print(f\"  â€¢ Routing: Orchestrator uses LLM-based intent analysis to select agent\")\n",
    "            print(f\"  â€¢ Protocol: A2A (Agent-to-Agent)\")\n",
    "            agents_called_list = []\n",
    "            if result.get(\"bull_case\"):\n",
    "                agents_called_list.append(\"Bull Agent (LangGraph)\")\n",
    "            if result.get(\"bear_case\"):\n",
    "                agents_called_list.append(\"Bear Agent (ADK)\")\n",
    "            if agents_called_list:\n",
    "                print(f\"  â€¢ Agent(s) Called: {', '.join(agents_called_list)}\")\n",
    "            else:\n",
    "                print(f\"  â€¢ Agent(s) Called: None (check orchestrator response)\")\n",
    "            print(f\"  â€¢ Expected Tools:\")\n",
    "            print(f\"    - Bull Agent: momentum_screener, growth_catalyst_finder, breakout_pattern_finder\")\n",
    "            print(f\"    - Bear Agent: risk_scanner, downside_catalyst_finder, exit_signal_monitor\")\n",
    "            print(f\"  â€¢ Note: Actual LLM and tool executions appear in remote agent traces\")\n",
    "        \n",
    "        # Force flush traces to ensure they're sent immediately\n",
    "        provider = trace.get_tracer_provider()\n",
    "        if hasattr(provider, 'force_flush'):\n",
    "            provider.force_flush()\n",
    "            print(\"\\nâœ“ Traces flushed to Arize\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nðŸ“ˆ BULL CASE for {ticker}:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(result.get(\"bull_case\", \"No bull case available\"))\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"\\nðŸ“‰ BEAR CASE for {ticker}:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(result.get(\"bear_case\", \"No bear case available\"))\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"\\nAnalysis Steps:\")\n",
    "        for step in result.get(\"analysis_steps\", []):\n",
    "            print(f\"  â€¢ {step}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nâœ— Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Query Function\n",
    "\n",
    "# Ensure trace imports are available\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "\n",
    "def ask_financial_advisor(query: str):\n",
    "    \"\"\"Convenience function to query the financial advisor.\n",
    "    \n",
    "    All operations are contained within a single trace to ensure proper trace propagation.\n",
    "    \"\"\"\n",
    "    initial_state: FinancialAdvisorState = {\n",
    "        \"customer_query\": query,\n",
    "        \"customer_profile\": {},\n",
    "        \"analysis_steps\": [],\n",
    "        \"bull_analysis\": \"\",\n",
    "        \"bear_analysis\": \"\",\n",
    "        \"final_advice\": \"\",\n",
    "        \"conversation_history\": [],\n",
    "    }\n",
    "    \n",
    "    # Create root span - all child operations will be part of this trace\n",
    "    with tracer.start_as_current_span(\"financial_advisor_query\", kind=trace.SpanKind.SERVER) as root_span:\n",
    "        root_span.set_status(Status(StatusCode.OK))\n",
    "        root_span.set_attribute(OPENINFERENCE_SPAN_KIND, SPAN_KIND_AGENT)\n",
    "        root_span.set_attribute(\"query\", query)\n",
    "        root_span.set_attribute(\"service.name\", \"financial-advisor-notebook\")\n",
    "        root_span.set_attribute(\"a2a.protocol\", True)\n",
    "        root_span.set_attribute(\"arize.project.name\", \"financial-advisor-notebook\")\n",
    "        \n",
    "        # Set input attributes\n",
    "        root_span.set_attribute(INPUT_VALUE, query)\n",
    "        root_span.set_attribute(INPUT_MIME_TYPE, \"text/plain\")\n",
    "        \n",
    "        # Log trace ID\n",
    "        ctx = root_span.get_span_context()\n",
    "        if ctx.is_valid:\n",
    "            trace_id = format(ctx.trace_id, '032x')\n",
    "            root_span.set_attribute(\"trace.id\", trace_id)\n",
    "            print(f\"ðŸ“Š Trace ID: {trace_id}\")\n",
    "        \n",
    "        # Invoke workflow - all spans will be children of root_span\n",
    "        result = app.invoke(initial_state)\n",
    "        \n",
    "        root_span.set_attribute(OUTPUT_VALUE, result.get(\"final_advice\", \"\")[:2000])\n",
    "        root_span.set_attribute(OUTPUT_MIME_TYPE, \"text/plain\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# result = ask_financial_advisor(\"Should I invest in renewable energy stocks?\")\n",
    "# print(result[\"final_advice\"])\n",
    "\n",
    "print(\"âœ“ Interactive query function ready\")\n",
    "print(\"  Usage: result = ask_financial_advisor('Your question here')\")\n",
    "print(\"  All operations will be contained within a single trace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Running Locally\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. **Local ADK Agents**: For the remote A2A protocol to work, you need ADK agents running locally:\n",
    "   - Bull Agent on port 8001\n",
    "   - Bear Agent on port 8002\n",
    "   \n",
    "   You can start them using:\n",
    "   ```bash\n",
    "   # In separate terminals\n",
    "   uvicorn src.bull_agent.server:a2a_app --port 8001\n",
    "   uvicorn src.bear_agent.server:a2a_app --port 8002\n",
    "   ```\n",
    "\n",
    "2. **Alternative**: Update `BULL_AGENT_URL` and `BEAR_AGENT_URL` to point to remote ADK agent endpoints if you have them deployed.\n",
    "\n",
    "3. **Anthropic API Key**: The API key is configured in the notebook. You can also set `ANTHROPIC_API_KEY` in your environment or `.env` file.\n",
    "\n",
    "### Trace Propagation\n",
    "\n",
    "**Important**: This notebook ensures all operations are contained within a single trace:\n",
    "\n",
    "- **Root Span**: Each query creates a root span (`financial_advisor_session` or `financial_advisor_query`) with `openinference.span.kind=AGENT`\n",
    "- **Child Spans**: All operations are created as child spans with proper semantic conventions:\n",
    "  - `parse_customer_query` (CHAIN) â†’ `llm_extract_profile` (LLM) with token counts and cost\n",
    "  - `get_bull_analysis` (AGENT) â†’ `a2a_call_bull_agent` (CLIENT) with input/output\n",
    "  - `get_bear_analysis` (AGENT) â†’ `a2a_call_bear_agent` (CLIENT) with input/output\n",
    "  - `synthesize_advice` (CHAIN) â†’ `llm_synthesize_advice` (LLM) with token counts and cost\n",
    "- **A2A Propagation**: When calling remote agents via A2A protocol, trace context is automatically injected into HTTP headers via HTTPX instrumentation\n",
    "- **Single Trace**: All spans share the same trace ID, ensuring complete visibility in Arize Cloud\n",
    "- **Input/Output**: All spans include `input.value` and `output.value` attributes with proper MIME types\n",
    "- **Cost Tracking**: LLM spans include token counts (`llm.token_count.*`) and cost calculations (`llm.cost.*`)\n",
    "\n",
    "The trace structure looks like:\n",
    "```\n",
    "financial_advisor_session (AGENT, root)\n",
    "â”œâ”€â”€ input.value: customer query\n",
    "â”œâ”€â”€ parse_customer_query (CHAIN)\n",
    "â”‚   â”œâ”€â”€ input.value: query\n",
    "â”‚   â””â”€â”€ llm_extract_profile (LLM)\n",
    "â”‚       â”œâ”€â”€ llm.model_name: claude-sonnet-4-20250514\n",
    "â”‚       â”œâ”€â”€ llm.token_count.prompt/completion/total\n",
    "â”‚       â”œâ”€â”€ llm.cost.input/output/total\n",
    "â”‚       â””â”€â”€ output.value: profile JSON\n",
    "â”œâ”€â”€ get_bull_analysis (AGENT)\n",
    "â”‚   â”œâ”€â”€ input.value: formatted query\n",
    "â”‚   â””â”€â”€ a2a_call_bull_agent (CLIENT)\n",
    "â”‚       â”œâ”€â”€ http.method: POST\n",
    "â”‚       â”œâ”€â”€ http.url: http://localhost:8001\n",
    "â”‚       â”œâ”€â”€ input.value: query\n",
    "â”‚       â””â”€â”€ output.value: bull analysis\n",
    "â”‚   â””â”€â”€ [Tool calls happen on bull agent server - should appear if agents are instrumented]\n",
    "â”œâ”€â”€ get_bear_analysis (AGENT)\n",
    "â”‚   â”œâ”€â”€ input.value: formatted query\n",
    "â”‚   â””â”€â”€ a2a_call_bear_agent (CLIENT)\n",
    "â”‚       â”œâ”€â”€ http.method: POST\n",
    "â”‚       â”œâ”€â”€ http.url: http://localhost:8002\n",
    "â”‚       â”œâ”€â”€ input.value: query\n",
    "â”‚       â””â”€â”€ output.value: bear analysis\n",
    "â”‚   â””â”€â”€ [Tool calls happen on bear agent server - should appear if agents are instrumented]\n",
    "â””â”€â”€ synthesize_advice (CHAIN)\n",
    "    â”œâ”€â”€ input.value: synthesis prompt\n",
    "    â””â”€â”€ llm_synthesize_advice (LLM)\n",
    "        â”œâ”€â”€ llm.model_name: claude-sonnet-4-20250514\n",
    "        â”œâ”€â”€ llm.token_count.prompt/completion/total\n",
    "        â”œâ”€â”€ llm.cost.input/output/total\n",
    "        â””â”€â”€ output.value: final advice\n",
    "â””â”€â”€ output.value: final advice\n",
    "```\n",
    "\n",
    "**Note on Tool Calls**: Tool calls (like `momentum_screener`, `risk_scanner`, etc.) are executed by the remote agents on their servers. If the agents are properly instrumented with OpenTelemetry, these tool calls should appear as child spans of the agent calls in Arize Cloud, connected via trace context propagation. Ensure your agent servers have tracing enabled to see tool call details.\n",
    "\n",
    "### Tracing\n",
    "\n",
    "- All traces are automatically sent to Arize Cloud using the configured Space ID and API Key\n",
    "- View traces at: https://app.arize.com\n",
    "- Each query creates a single trace containing all operations\n",
    "- Trace IDs are logged to console for verification\n",
    "\n",
    "### Architecture Benefits\n",
    "\n",
    "- **LangGraph**: Provides stateful, cyclic workflows without Pydantic dependencies\n",
    "- **ADK Remote A2A**: Enables distributed agent communication without tight coupling\n",
    "- **Local Execution**: No Google Cloud Console required - everything runs locally\n",
    "- **Arize Observability**: Full trace visibility across the entire workflow with proper trace propagation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
